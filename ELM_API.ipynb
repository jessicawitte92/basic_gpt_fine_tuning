{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook demonstrate the process of fine tuning a GPT model using the OpenAI API endpoint"
      ],
      "metadata": {
        "id": "dAFSifTo8wSk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Install packages"
      ],
      "metadata": {
        "id": "vvtpuvd29FEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install required packages for Python environment\n",
        "!pip install openai"
      ],
      "metadata": {
        "id": "V7RW9VZw8nP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import required packages\n",
        "import os\n",
        "from openai import OpenAI\n",
        "import json\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "XfhIHCAr32K3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To be able to use OpenAI you will need to connect to OpenAI via a API key. You can find your Secret API key on the [API key page](https://platform.openai.com/api-keys).\n",
        "\n",
        "Check out our [Best Practices for API Key Safety to learn how you can keep your API key protected](https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety)."
      ],
      "metadata": {
        "id": "9QeEhVFp9o8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Using your API key, start a new OpenAI\n",
        "session with your credentials\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = 'paste API key here'\n",
        "client=OpenAI()\n"
      ],
      "metadata": {
        "id": "chIm3SeK4Hp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import your training data\n",
        "You can import your training data either directly via Github (If you are set up there) or by using your google drive if you are using Google Colab."
      ],
      "metadata": {
        "id": "OMHr1pmQ-xGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount Google Drive (Only if you want to work via Google Colab )\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "0QLPJuOj_jsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import data for fine tuning. The data must be in JSON Lines format and must contain at least 10 examples in OpenAI 'message' structure.\n",
        "OpenAI documentation on formatting can be found here: https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset\n"
      ],
      "metadata": {
        "id": "aW0jFW_3_TjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file_path='/content/drive/MyDrive/training_data.json'\n",
        "\n",
        "client.files.create(\n",
        "  file=open(file_path, 'rb'),\n",
        "  purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "\n",
        "#This code block will return a file name as 'training_file'. Take note of this for the next block.\n",
        "#Alternatively, store the file name as a new variable."
      ],
      "metadata": {
        "id": "0b6BaF624PBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code block will return a file name as 'training_file'. Take note of this for the next block.\n",
        "\n",
        "Alternatively, store the file name as a new variable.\n",
        "\n",
        "### Fine Tuning\n",
        "\n",
        "Create a new fine tuning job using the file created in the last step.\n",
        "\n",
        "Additional parameters you can include are outlined in OpenAI's documentation: https://platform.openai.com/docs/api-reference/fine-tuning"
      ],
      "metadata": {
        "id": "MNJYVVpg_bPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "client.fine_tuning.jobs.create(\n",
        "  training_file='paste the name of training_file from previous step here',\n",
        "  model=\"gpt-3.5-turbo\" #Select specific GPT model for fine tuning. See the OpenAI documentation for more information, including costs.\n",
        ")"
      ],
      "metadata": {
        "id": "l9aep8NA4Q2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As in the step above, this code block will return the name of fine tuning job. Take note of this for the next block."
      ],
      "metadata": {
        "id": "6n6zZWBU_sIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To check the status of a fine tuning job:\n",
        "client.fine_tuning.jobs.retrieve('paste fine tuning job from previous step here')\n"
      ],
      "metadata": {
        "id": "OetuJBW941Eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensure the fine tuning job is running and no errors have arisen.\n",
        "\n",
        "When the fine tuning has finished, running this line of code will show that the output of the fine_tuned_model argument has been populated with a unique name (which will start with 'ft: '). As in the previous steps, take note of the model's name.\n",
        "\n",
        "Depending on the size of the training file, fine tuning can take some time. As long as the status shows the job is 'running', you can safely assume no errors have arisen.\n"
      ],
      "metadata": {
        "id": "ubCY3FXi_zJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To cancel a fine-tuning job:\n",
        "#client.fine_tuning.jobs.cancel('paste fine tuning job from previous step here')\n",
        "\n",
        "#To delete a fine-tuned model:\n",
        "#client.models.delete('paste fine tuning job from previous step here')"
      ],
      "metadata": {
        "id": "5VM5iQ_2_-E-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the system message, which sets an overall identity or 'personality' for the model, and a question for testing the model:\n",
        "\n",
        "system_msg: 'You are MunroBot, and you answer questions about the mountains in Scotland in the voice of 19th-century moutaineer Hugh Munro.'\n",
        "input_msg: 'MunroBot, how many peaks are in the Cuillin Ridge?'\n",
        "\n"
      ],
      "metadata": {
        "id": "AMyvxc9w5Jv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test the model using the system message and input question:\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model='name of fine-tuned model',\n",
        "  messages=[\n",
        "    {'role': 'system', 'content': system_msg},\n",
        "    {\"role\": \"user\", \"content\": input_msg}\n",
        "  ]\n",
        ")\n",
        "\n",
        "#Print the model's response:\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "id": "VhnET0mXC4p5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Depending on your use case, you can plug the fine-tuned model into a basic chatbot interface with the gradio package:\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "def chatbot(prompt):\n",
        "  completion = client.chat.completions.create(\n",
        "      model='name of fine-tuned model',\n",
        "      temperature=0.6,\n",
        "      messages=[\n",
        "    {'role': 'system', 'content': system_msg},\n",
        "    {\"role\": \"user\", \"content\": input_msg}\n",
        "  ]\n",
        ")\n",
        "  return (completion.choices[0].message.content)\n",
        "\n",
        "iface = gr.Interface(fn=chatbot, inputs='text', outputs='text')\n",
        "iface.launch(share=True)"
      ],
      "metadata": {
        "id": "caSDvxZUaO8C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
